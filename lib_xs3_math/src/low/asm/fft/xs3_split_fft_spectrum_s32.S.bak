
#if defined(__XS3A__)
#ifndef XS3_MATH_NO_ASM

/*  
headroom_t xs3_split_fft_spectrum_s32(
    complex_s32_t* X,
    const unsigned N);
*/

#include "../asm_helper.h"

.text
.issue_mode dual

#define NSTACKWORDS     (8)

#define FUNCTION_NAME   xs3_split_fft_spectrum_s32


.section    .cp.rodata, "ac", @progbits
.align 4
L_neg_j_vect:
    .word 0x00000000, -0x40000000, 0x00000000, -0x40000000, 0x00000000, -0x40000000, 0x00000000, -0x40000000
L_comp_conj_vect:
    .word 0x40000000, -0x40000000, 0x40000000, -0x40000000, 0x40000000, -0x40000000, 0x40000000, -0x40000000
L_zero_vect:
    .word 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000

ASM_PREAMBLE(FUNCTION_NAME)

#define X       r0
#define N       r1

FUNCTION_NAME:
    {   dualentsp NSTACKWORDS                                                               }
    {   std r4, r5, sp[3]                                                                   }
    {   std r6, r7, sp[2]                                                                   }
    {   std r8, r9, sp[1]                                                                   }
    {   ldc r11, 0                              ;   stw r10, sp[1]                          }
    {                                           ;   vsetc r11                               }

#if (XS3_CONFIG_MIN_FFT_LEN <= 8)
    {   shr r10, N, 3                           ;   shr r11, N, 4                           }
  #if (XS3_CONFIG_MIN_FFT_LEN <= 4)
    {                                           ;   bf r10, .L_fft_length_4                 }
  #endif
    {                                           ;   bf r11, .L_fft_length_8                 }
    {                                           ;   bu .L_reverse_elements                  }
#endif

#if (CONFIG_MIN_FFT_LEN <= 4)
.L_fft_length_4:

    // If the FFT length is 4, just do the work here. This keeps the code below simpler.
    {   mkmsk r10, 8                            ;                                           }
    {   shl r11, r10, 16                        ;   ldw r4, X[1]                            }
    {   add r10, r10, r11                       ;   ldw r5, X[4]                            }
    {   ldc r11, 1                              ;   stw r4, X[4] /* X[2].re <- X[0].im */   }
    {   not r10, r10                            ;   stw r5, X[1] /* X[0].im <- X[2].re */   }
        vlashr X[0], r11
        vstrpv X[0], r10
        ldd r5, r4, X[1]
        ldd r7, r6, X[3]
    {   add r10, r4, r6                         ;   sub r11, r5, r7                         }
        std r11, r10, X[1]
    {   add r10, r5, r7                         ;   sub r11, r6, r4                         }
        std r11, r10, X[3]
    {                                           ;   vldd X[0]                               }
    {                                           ;   vstd X[0]                               }
    {                                           ;   bu .L_finish                            }

#endif

#if (XS3_CONFIG_MIN_FFT_LEN <= 8)
.L_fft_length_8:
    // If the FFT length is 8, we can't use the VPU to swap the 2 elements that need swapping, so just
    // do it here and skip that loop.
        ldd r4, r5, X[5]
        ldd r6, r7, X[7]
        std r4, r5, X[7]
        std r6, r7, X[5]
        bu .L_split_the_spectrum
#endif


.L_reverse_elements:

/*
    Goal is to change [A, B, C, D] to  [D, C, B, A]
    2x VLMACCR changes it to [D, A, B, C]  which has D and B in the correct place
        (2 because 32-bit mode and elements are complex)
    Then we can do partial stores for A and C using different masks and offsets.
    A's offset is + 16 bytes, C's is - 16 bytes.
    A's mask is 0x0000FF00  and C's is 0xFF000000
*/

#define i       r2
#define X_A     r3
#define X_C     r4
#define mask_A  r5
#define mask_C  r6
#define _32     r7
#define zero    r8
#define _16     r9
#define X_hi    r10
#define X_lo    r11

        ldaw r11, cp[L_zero_vect]
    {   ldc _32, 32                             ;   mov zero, r11                           }
    {   mkmsk mask_A, 8                         ;   vclrdr                                  }
    {   ldc _16, 16                             ;   shl mask_A, mask_A, 8                   }
    {   shr i, N, 4                             ;   shl mask_C, mask_A, 16                  }
        ldaw X_lo, X[N]
        ldaw X_hi, X_lo[N]
    {   add X_lo, X_lo, 8                       ;   sub X_hi, X_hi, _32                     }

.L_rev_loop:
        {   add X_A, X_hi, _16                      ;   vldc X_hi[0]                            }
        {   sub X_C, X_hi, _16                      ;   vldr X_lo[0]                            }
        {   sub i, i, 1                             ;   vlmaccr zero[0]                         }
        {                                           ;   vlmaccr zero[0]                         }
        {   sub X_hi, X_hi, _32                     ;   vstr X_hi[0]                            }
            vstrpv X_A[0], mask_A
            vstrpv X_C[0], mask_C
        {   add X_A, X_lo, _16                      ;   vstc X_lo[0]                            }
        {   sub X_C, X_lo, _16                      ;   vldr X_lo[0]                            }
        {                                           ;   vlmaccr zero[0]                         }
        {                                           ;   vlmaccr zero[0]                         }
        {   add X_lo, X_lo, _32                     ;   vstr X_lo[0]                            }
            vstrpv X_A[0], mask_A
            vstrpv X_C[0], mask_C
        {                                           ;   bt i, .L_rev_loop                       }

#undef i
#undef X_A
#undef X_C
#undef mask_A
#undef mask_C
#undef _32
#undef zero
#undef _16
#undef X_hi
#undef X_lo


// #undef S_re
// #undef S_im
// #undef T_re
// #undef T_im
// #undef X_lo
// #undef X_hi

.L_split_the_spectrum:

#define X_lo    X
#define i       r2
#define _32     r3
#define X_hi    r4
#define DC_im   r5
#define DC_re   r6
#define Ny_im   r7
#define Ny_re   r8

    // x = [DC.re - Ny.im, Ny.re + DC.im, DC.re + Ny.im, -Ny.re + DC.im]

    // If I set [X[0].re, X[0].im, X[K].re, X[k].im] to the vector above, then I can just compute
    // the results for bins 0 and K along with everything else. Then I'm guaranteed that the number
    // of elements is a multiple of 4, which means this loop will have no tail, AND it will have
    // captured the headroom of the vector (although it will be the lesser of the lower and upper
    // halves)
    {   ldc _32, 32                             ;   shr i, N, 1                             }
        ldd DC_im, DC_re, X[0]
        ldd Ny_im, Ny_re, X[i]
    {   sub r9, DC_re, Ny_im                    ;   add r11, DC_im, Ny_re                   }
        std r11, r9, X[0]
    {   add r9, DC_re, Ny_im                    ;   sub r11, DC_im, Ny_re                   }
        std r11, r9, X[i]  

#undef DC_re
#undef DC_im
#undef Ny_re
#undef Ny_im

#define conj_vec    r5

    {   ldaw X_hi, X_lo[N]                                                                  }
    {   ldc r11, 0x0080                                                                     }
    {   shr i, i, 2                             ;   vsetc r11                               }
        ldaw r11, cp[L_neg_j_vect]
    {                                           ;   vldc r11[0]                             }
        ldaw r11, cp[L_comp_conj_vect]
    {                                           ;   bu .L_syzygy                            }

.align 16
.L_syzygy:
        {   sub i, i, 1                             ;   vldr r11[0]                             }
        {                                           ;   vlmul X_hi[0]                           }
        {                                           ;   vladsb X_lo[0]                          }
        {   add X_lo, X_lo, _32                     ;   vstr X_lo[0]                            }
        {                                           ;   vcmr                                    }
        {                                           ;   vcmi                                    }
        {   add X_hi, X_hi, _32                     ;   vstr X_hi[0]                            }
        {                                           ;   bt i, .L_syzygy                         }


.L_finish:
    {   ldc r0, 31                              ;   vgetc r11                               }
    {   zext r11, 5                             ;                                           }
    {   sub r0, r0, r11                         ;   ldw r10, sp[1]                          }

    {   ldd r8, r9, sp[1]                                                                   }
    {   ldd r6, r7, sp[2]                                                                   }
    {   ldd r4, r5, sp[3]                                                                   }
    {   retsp NSTACKWORDS                                                                   }

ASM_POSTAMBLE(FUNCTION_NAME, NSTACKWORDS)







#endif //!defined(XS3_MATH_NO_ASM)
#endif //defined(__XS3A__)